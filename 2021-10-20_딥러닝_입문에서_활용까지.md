[→ Open in Slid](https://slid.cc/docs/44ca05c533e84d7f92e7690da383265d)


---

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/e58aeb0b-fc74-458d-8443-e0ae631b4ab4.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=386.0738791296997)


전통적인 programming:

- Rules + data -> inference -> Answers

- Answers + data -> inference -> Rule

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/e7bb4f0c-ed87-4840-ac4a-b8f8c8859ddd.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=459.9003300324249)


학습하지 않은 데이터가 들어갔을때 좋은 prediction을 주는 것.


Deep Learning:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/4d1cf9d3-ae0c-4d78-84ed-f16b2628487f.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=482.3919460209808)

- 이제는 이 정의가 조금 바뀌었다고 생각됨.


Perceptron

- weight initialization (randomization)

- loss function (cost/error/objective function)

  - MSE for regression

  - Classification 할때는 cross-entropy같은 것을 쓰게됨.


Gradient Descent

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/d71e527c-196e-4475-9c32-6f721302a2a1.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=926.9494030076294)

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/96261aab-2b49-4e52-ba5e-431da2d202f2.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=828.4508080648499)

### Training vs. test dataset:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/5fe4c394-8490-4f13-9da7-db06b8fe7dbf.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=1028.271052940872)

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/822d44bb-260f-4371-a92e-c7a9f8afac7a.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=1065.935707923706)


Learning rate 는 batch size에 따라 조정해야함.

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/44ae53f3-be39-463c-b78e-11337270efc0.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=1229.1267028779296)


합성함수, Chain Rule로 한단계씩 미분.

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/ffc24ea9-3245-49bb-96cd-7e88b174c48a.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=b85a573fa1c7454094a2daf56d6e3908&start=1267.563458944687)

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/fc7f7cb5-6d60-41bf-bdfd-5f32f0bf4af7.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=5030b67a91924e2990644bdb2d82d186&start=792.8178601506805)

- AutoGraph - Debugging이 끝나고 decorator (@tf.function)을 붙여서 하면 graph mode

### Using Keras:

- Sequential API

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/c99c1b6b-9e9b-4a7f-b56f-8ba9357a4b49.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=904.9130651792908)


**tf.keras** will be the main-line.

- Functional API

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/b9493a41-d66f-4314-82d9-1ad74eb5d895.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1142.2557818760224)

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/371b1284-aca3-4608-8d85-af04e22415b5.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1167.8719799027251)


하나의 결과값이 여러개의 layer에 input으로 들어가야할때 이렇게 진행해야함.

- 예제: google inception의 구조. 초록 layer들이 multiple 파랑과 빨강 layer에 들어감.

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/dfb0eb8c-db70-4866-82bd-83ca6ad1834a.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1260.8840811735688)

### Custom Layer example:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/adcfcb14-b734-4ac4-bd03-9dfd81e73eac.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1450.6105869351502)

### Custom Model:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/987ac6a5-6234-42df-8caf-87022c4891c3.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1545.4793379198913)

### 학습하는법:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/da579293-6663-4281-ab8f-15144b74be53.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1614.1381750267028)


Model with call backs

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/b0bd99c6-d0ee-4db9-a17a-fbdd60544f49.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1662.6140110457764)

- EarlyStopping(); 특정 parameter가 limit을 reach 하면 over-fitting을 막기위해 stop.

### Gradient tape:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/f0d2e0cb-8bb7-45d4-b33e-3751e1d0747c.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1698.6336489904631)

- tape 안에 모델 입력부터 loss까지의 과정을 입력.

- **logits** and **loss** in the example.

### TensorFlow recommendations:

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/209bf124-1b79-49c6-a462-ba362fc7d610.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1869.429607087738)


\-tf.data.Datasets: 컴퓨터 data를 GPU에 feeding 해주는 것.

### 혹시 tensorFlow1.x 기준 코드를 tensorFlow2.0로 돌리는 법

[![딥러닝 입문에서 활용까지 image](https://slid-capture.s3.ap-northeast-2.amazonaws.com/public/capture_images/44ca05c533e84d7f92e7690da383265d/107e960e-3576-4281-8c93-1f27d32766c0.jpg)](https://slid.cc/vdocs/44ca05c533e84d7f92e7690da383265d?v=6a9c5bc55e754481a74faad9e7633e9c&start=1935.6972798912811)






